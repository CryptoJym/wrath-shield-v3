/**
 * SpeechMiner v2 - Confidence Flag Detection Engine
 *
 * Detects confidence-related flags from transcripts and chat input
 * using lexicon-based pattern matching and heuristic severity scoring.
 *
 * Performance target: â‰¤150ms per 1,000 characters
 */

import {
  ALL_LEXICONS,
  CategoryLexicon,
  FlagPattern,
  ASSURED_MARKERS_LEXICON,
} from './speechMiner/lexicons';

/**
 * Output flag structure
 */
export interface ConfidenceFlag {
  phrase: string; // The detected phrase
  snippet: string; // Context snippet (50 chars before + phrase + 50 chars after)
  category: string; // Category name (hedges, apologies, etc.)
  severity: 1 | 2 | 3 | 4 | 5; // Severity score
  suggestion_id: string; // Unique suggestion identifier
  position: number; // Character position in original text
}

/**
 * Analysis result structure
 */
export interface AnalysisResult {
  flags: ConfidenceFlag[];
  text: string;
  processingTime: number; // Milliseconds
  flagCount: number;
  averageSeverity: number;
  hasHighSeverityFlags: boolean; // severity >= 4
}

/**
 * Main SpeechMiner class
 */
export class SpeechMiner {
  private intensifierWords: Set<string>;
  private contextWindow = 50; // Characters for snippet context
  private clusteringWindow = 50; // Words for flag clustering detection

  constructor() {
    // Compile all intensifier words from all lexicons for fast lookup
    this.intensifierWords = new Set();
    ALL_LEXICONS.forEach((lexicon) => {
      lexicon.intensifiers.forEach((word) => {
        this.intensifierWords.add(word.toLowerCase());
      });
    });
  }

  /**
   * Analyze text and detect confidence flags
   */
  public analyze(text: string): AnalysisResult {
    const startTime = performance.now();

    const flags: ConfidenceFlag[] = [];
    const normalizedText = text.toLowerCase();

    // Process each category lexicon
    for (const lexicon of ALL_LEXICONS) {
      const categoryFlags = this.detectCategory(text, normalizedText, lexicon);
      flags.push(...categoryFlags);
    }

    // Sort by position for clustering analysis
    flags.sort((a, b) => a.position - b.position);

    // Apply clustering bonus (+1 severity if 3+ flags within clustering window)
    this.applyClustering(flags, text);

    // Cap all severities at 5
    flags.forEach((flag) => {
      flag.severity = Math.min(5, flag.severity) as 1 | 2 | 3 | 4 | 5;
    });

    const endTime = performance.now();
    const processingTime = endTime - startTime;

    // Calculate statistics
    const flagCount = flags.length;
    const averageSeverity =
      flagCount > 0
        ? flags.reduce((sum, flag) => sum + flag.severity, 0) / flagCount
        : 0;
    const hasHighSeverityFlags = flags.some((flag) => flag.severity >= 4);

    return {
      flags,
      text,
      processingTime,
      flagCount,
      averageSeverity,
      hasHighSeverityFlags,
    };
  }

  /**
   * Detect flags for a specific category
   */
  private detectCategory(
    originalText: string,
    normalizedText: string,
    lexicon: CategoryLexicon
  ): ConfidenceFlag[] {
    const flags: ConfidenceFlag[] = [];

    for (const pattern of lexicon.patterns) {
      let matches: RegExpMatchArray[];

      if (pattern.pattern instanceof RegExp) {
        // Use regex to find all matches
        const globalRegex = new RegExp(pattern.pattern.source, 'gi');
        const matchesArray: RegExpMatchArray[] = [];
        let match: RegExpExecArray | null;

        while ((match = globalRegex.exec(normalizedText)) !== null) {
          matchesArray.push(match);
        }
        matches = matchesArray;
      } else {
        // Simple string search (case-insensitive)
        const searchTerm = pattern.pattern.toLowerCase();
        matches = [];
        let index = normalizedText.indexOf(searchTerm);

        while (index !== -1) {
          const match: RegExpMatchArray = [searchTerm];
          match.index = index;
          matches.push(match);
          index = normalizedText.indexOf(searchTerm, index + 1);
        }
      }

      // Process each match
      for (const match of matches) {
        const matchedPhrase = match[0];
        const position = match.index!;

        // Calculate severity
        let severity = pattern.baseWeight;

        // Add intensifier bonus (check 3 words before the match)
        const beforeText = normalizedText.substring(
          Math.max(0, position - 20),
          position
        );
        const intensifierBonus = this.countIntensifiers(beforeText);
        severity += intensifierBonus;

        // Generate snippet (context around the match)
        const snippetStart = Math.max(0, position - this.contextWindow);
        const snippetEnd = Math.min(
          originalText.length,
          position + matchedPhrase.length + this.contextWindow
        );
        let snippet = originalText.substring(snippetStart, snippetEnd);

        // Add ellipsis if truncated
        if (snippetStart > 0) snippet = '...' + snippet;
        if (snippetEnd < originalText.length) snippet = snippet + '...';

        // Generate suggestion ID (category + pattern index + position)
        const suggestionId = `${lexicon.name}-${lexicon.patterns.indexOf(
          pattern
        )}-${position}`;

        flags.push({
          phrase: originalText.substring(position, position + matchedPhrase.length),
          snippet: snippet.trim(),
          category: lexicon.name,
          severity: Math.min(5, severity) as 1 | 2 | 3 | 4 | 5,
          suggestion_id: suggestionId,
          position,
        });
      }
    }

    return flags;
  }

  /**
   * Count intensifier words in text
   */
  private countIntensifiers(text: string): number {
    const words = text.toLowerCase().split(/\s+/);
    return words.filter((word) => this.intensifierWords.has(word)).length;
  }

  /**
   * Apply clustering bonus to flags
   * If 3+ flags within clusteringWindow words, add +1 to severity
   */
  private applyClustering(flags: ConfidenceFlag[], text: string): void {
    if (flags.length < 3) return;

    // Calculate word positions for each flag
    const textBeforePosition = (pos: number) =>
      text.substring(0, pos).split(/\s+/).length;

    for (let i = 0; i < flags.length; i++) {
      const currentWordPos = textBeforePosition(flags[i].position);

      // Count flags within clustering window
      let nearbyFlags = 1; // Count current flag

      // Check flags before
      for (let j = i - 1; j >= 0; j--) {
        const prevWordPos = textBeforePosition(flags[j].position);
        if (currentWordPos - prevWordPos <= this.clusteringWindow) {
          nearbyFlags++;
        } else {
          break;
        }
      }

      // Check flags after
      for (let j = i + 1; j < flags.length; j++) {
        const nextWordPos = textBeforePosition(flags[j].position);
        if (nextWordPos - currentWordPos <= this.clusteringWindow) {
          nearbyFlags++;
        } else {
          break;
        }
      }

      // Apply clustering bonus if 3+ flags nearby
      if (nearbyFlags >= 3) {
        flags[i].severity = Math.min(
          5,
          flags[i].severity + 1
        ) as 1 | 2 | 3 | 4 | 5;
      }
    }
  }

  /**
   * Quick scan for high-severity flags only (faster, for real-time use)
   */
  public quickScan(text: string): boolean {
    const normalizedText = text.toLowerCase();

    // Check only high-severity patterns (base weight >= 4)
    for (const lexicon of ALL_LEXICONS) {
      for (const pattern of lexicon.patterns) {
        if (pattern.baseWeight >= 4) {
          if (pattern.pattern instanceof RegExp) {
            if (pattern.pattern.test(normalizedText)) {
              return true;
            }
          } else {
            if (normalizedText.includes(pattern.pattern.toLowerCase())) {
              return true;
            }
          }
        }
      }
    }

    return false;
  }

  /**
   * Get confidence score (0-100, higher is better)
   * Based on inverse of average severity and flag density
   */
  public calculateConfidenceScore(result: AnalysisResult): number {
    if (result.flagCount === 0) return 100;

    // Penalize based on average severity (0-5 scale)
    const severityPenalty = (result.averageSeverity / 5) * 50;

    // Penalize based on flag density (flags per 100 words)
    const wordCount = result.text.split(/\s+/).length;
    const flagDensity = (result.flagCount / wordCount) * 100;
    const densityPenalty = Math.min(30, flagDensity * 5);

    // Extra penalty for high-severity flags
    const highSeverityPenalty = result.hasHighSeverityFlags ? 10 : 0;

    const score = Math.max(
      0,
      100 - severityPenalty - densityPenalty - highSeverityPenalty
    );

    return Math.round(score);
  }

  /**
   * Get category breakdown
   */
  public getCategoryBreakdown(
    result: AnalysisResult
  ): Record<string, { count: number; averageSeverity: number }> {
    const breakdown: Record<
      string,
      { count: number; totalSeverity: number; averageSeverity: number }
    > = {};

    result.flags.forEach((flag) => {
      if (!breakdown[flag.category]) {
        breakdown[flag.category] = {
          count: 0,
          totalSeverity: 0,
          averageSeverity: 0,
        };
      }
      breakdown[flag.category].count++;
      breakdown[flag.category].totalSeverity += flag.severity;
    });

    // Calculate averages
    Object.keys(breakdown).forEach((category) => {
      breakdown[category].averageSeverity =
        breakdown[category].totalSeverity / breakdown[category].count;
      delete (breakdown[category] as any).totalSeverity;
    });

    return breakdown;
  }

  /**
   * Check if text shows confidence (positive detection)
   */
  public detectConfidence(text: string): boolean {
    const normalizedText = text.toLowerCase();

    for (const pattern of ASSURED_MARKERS_LEXICON.patterns) {
      if (pattern.pattern instanceof RegExp) {
        if (pattern.pattern.test(normalizedText)) {
          return true;
        }
      } else {
        if (normalizedText.includes(pattern.pattern.toLowerCase())) {
          return true;
        }
      }
    }

    return false;
  }
}

/**
 * Singleton instance for convenient usage
 */
let speechMinerInstance: SpeechMiner | null = null;

export function getSpeechMiner(): SpeechMiner {
  if (!speechMinerInstance) {
    speechMinerInstance = new SpeechMiner();
  }
  return speechMinerInstance;
}

/**
 * Convenience function for quick analysis
 */
export function analyzeText(text: string): AnalysisResult {
  return getSpeechMiner().analyze(text);
}
